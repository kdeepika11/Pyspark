{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "584b0f4c-2cd6-4f72-8663-99297b332f60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "orders = spark.table(\"workspace.default.silver_orders\")\n",
    "customers = spark.table(\"workspace.default.silver_customers\")\n",
    "\n",
    "narrow_df= (orders\n",
    ".select(\"CustomerID\",\"OrderId\",\"Amount\",\"OrderDate\")\n",
    ".filter(F.col(\"Amount\")>=50)\n",
    ".withColumn(\"Amount2\",F.col(\"Amount\")*2)\n",
    ")\n",
    "narrow_df.explain(True)\n",
    "display(narrow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44ea984-1f6a-4047-8d7f-486bc3b7bdf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gb = (orders\n",
    "  .groupBy(\"CustomerId\")\n",
    "  .agg(F.sum(\"Amount\").alias(\"TotalAmount\"))\n",
    ")\n",
    "\n",
    "gb.explain(True)\n",
    "display(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "32f40465-d2f9-4671-89f7-7d02eda8c0c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Current partitions: \" ,spark.conf.get(\"spark.sql.shuffle.partitions\"))\n",
    "orders.explain(True)\n",
    "orders_rep=orders.coalesce(2)\n",
    "orders_rep.explain(True)\n",
    "display(orders_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "aa4b2550-6c43-4df9-9619-28cf6141666c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import time\n",
    "\n",
    "orders = spark.table(\"workspace.default.silver_orders\")\n",
    "customers = spark.table(\"workspace.default.silver_customers\")\n",
    "\n",
    "heavy = (orders\n",
    "  .join(customers.select(\"CustomerId\",\"Country\"), \"CustomerId\", \"left\")\n",
    "  .groupBy(\"Country\")\n",
    "  .agg(\n",
    "      F.count(\"*\").alias(\"TotalOrders\"),\n",
    "      F.sum(\"Amount\").alias(\"TotalRevenue\")\n",
    "  )\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "heavy.count()   # action 1 (triggers full compute)\n",
    "t1 = time.time()\n",
    "\n",
    "heavy.count()   # action 2 (recomputes again)\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"No cache - Run1 seconds:\", round(t1 - t0, 3))\n",
    "print(\"No cache - Run2 seconds:\", round(t2 - t1, 3))\n",
    "\n",
    "\n",
    "heavy_cached = heavy.cache() \n",
    "t0 = time.time()\n",
    "heavy_cached.count()           # materialize cache\n",
    "t1 = time.time()\n",
    "\n",
    "heavy_cached.count()           # should be faster\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"With cache - Materialize seconds:\", round(t1 - t0, 3))\n",
    "print(\"With cache - Run2 seconds:\", round(t2 - t1, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d0deb7c8-2532-4ad9-9346-3b720c7db4ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "orders = spark.table(\"workspace.default.silver_orders\")\n",
    "customers = spark.table(\"workspace.default.silver_customers\").select(\"CustomerId\", \"Country\")\n",
    "j_normal = orders.join(customers, \"CustomerId\", \"left\")\n",
    "j_normal.explain(True)\n",
    "#j_broadcast = orders.join(F.broadcast(customers), \"CustomerId\", \"left\")\n",
    "#j_broadcast.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275af802-2cdc-49bb-8794-992cd1d58f89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "orders = spark.table(\"workspace.default.silver_orders\")\n",
    "\n",
    "key_counts = (orders\n",
    "  .groupBy(\"CustomerId\")\n",
    "  .agg(F.count(\"*\").alias(\"cnt\"))\n",
    "  .orderBy(F.col(\"cnt\").desc())\n",
    ")\n",
    "\n",
    "display(key_counts)\n",
    "total = orders.count()\n",
    "\n",
    "skew_report = (key_counts\n",
    "  .withColumn(\"share_pct\", F.round((F.col(\"cnt\") / F.lit(total)) * 100, 2))\n",
    ")\n",
    "display(skew_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c7ee1ee-4715-43d3-96dd-54c56ff5c959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "salt_n = 10\n",
    "fact_salted = orders.withColumn(\"salt\", (F.rand() * salt_n).cast(\"int\"))\n",
    "display(fact_salted)\n",
    "\n",
    "salts= spark.range(salt_n).withColumnRenamed(\"id\", \"salt\")\n",
    "#dim_salted=customers.crossjoin(salts)\n",
    "display(salts)\n",
    "#display(dim_salted)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Explainplan",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
